---
phase: 04-solution-extraction-export
plan: 04
type: execute
wave: 3
depends_on: ["04-01", "04-02", "04-03"]
files_modified:
  - src/solvers/solver_types.jl
  - src/solvers/solver_interface.jl
  - src/solvers/solution_extraction.jl
  - src/solvers/Solvers.jl
  - src/analysis/solution_exporter.jl
  - test/unit/test_solution_extraction.jl
  - test/unit/test_solution_exporter.jl
autonomous: true
gap_closure: true
must_haves:
  truths:
    - "solve_model!() automatically attempts nodal LMP extraction when system has buses and lines"
    - "Nodal LMP failure does not break solve pipeline (try/catch with warning)"
    - "get_pricing_dataframe() returns nodal LMPs when available, falls back to zonal PLD"
    - "Nodal LMPs are stored in SolverResult.nodal_lmps to avoid recomputation"
    - "export_csv() writes nodal_lmps.csv when nodal data available"
    - "export_json() includes nodal_lmps section when nodal data available"
  artifacts:
    - path: "src/solvers/solver_types.jl"
      provides: "nodal_lmps field on SolverResult"
      contains: "nodal_lmps"
    - path: "src/solvers/solver_interface.jl"
      provides: "Auto-call nodal LMP extraction in solve pipeline"
      contains: "get_nodal_lmp_dataframe"
    - path: "src/solvers/solution_extraction.jl"
      provides: "Unified get_pricing_dataframe with nodal-first fallback logic"
      contains: "get_pricing_dataframe"
    - path: "src/analysis/solution_exporter.jl"
      provides: "Nodal LMP CSV and JSON export"
      contains: "nodal_lmps"
  key_links:
    - from: "src/solvers/solver_interface.jl"
      to: "src/solvers/solution_extraction.jl"
      via: "solve_model! calls get_nodal_lmp_dataframe"
      pattern: "get_nodal_lmp_dataframe"
    - from: "src/solvers/solution_extraction.jl"
      to: "src/solvers/solver_types.jl"
      via: "get_pricing_dataframe reads result.nodal_lmps"
      pattern: "result\\.nodal_lmps"
    - from: "src/analysis/solution_exporter.jl"
      to: "src/solvers/solver_types.jl"
      via: "export_csv/export_json read result.nodal_lmps"
      pattern: "result\\.nodal_lmps"
---

<objective>
Integrate nodal LMP extraction into the solve pipeline so that solve_model!() automatically attempts bus-level pricing when network data is present, stores results in SolverResult, and exposes them through get_pricing_dataframe() and CSV/JSON export.

Purpose: Close UAT gap -- user expects default pricing to try nodal LMPs first with zonal PLD as fallback, but currently nodal LMPs require a separate explicit call.

Output: Updated SolverResult with nodal_lmps field, auto-extraction in solve_model!(), unified pricing in get_pricing_dataframe(), and nodal LMP export in CSV/JSON.
</objective>

<execution_context>
@/home/pedro/.claude/get-shit-done/workflows/execute-plan.md
@/home/pedro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-solution-extraction-export/04-03-SUMMARY.md
@src/solvers/solver_types.jl
@src/solvers/solver_interface.jl
@src/solvers/solution_extraction.jl
@src/solvers/Solvers.jl
@src/analysis/solution_exporter.jl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add nodal_lmps field to SolverResult and integrate into solve pipeline</name>
  <files>
    src/solvers/solver_types.jl
    src/solvers/solver_interface.jl
    src/solvers/solution_extraction.jl
    src/solvers/Solvers.jl
    src/analysis/solution_exporter.jl
  </files>
  <action>
**1. Add `nodal_lmps` field to SolverResult** (`src/solvers/solver_types.jl`):

Add a new field to the mutable struct `SolverResult` (line 142-157):
```julia
nodal_lmps::Union{DataFrame,Nothing}
```
Place it after `log_file` (line 156). Also update the outer constructor (lines 160-192) to accept `nodal_lmps::Union{DataFrame,Nothing} = nothing` as a keyword argument and pass it to the inner constructor. Update the docstring to document the new field: `- nodal_lmps::Union{DataFrame,Nothing}: Bus-level nodal LMPs from DC-OPF (auto-populated by solve_model! when network data available)`. The `SolverResult` struct already uses `DataFrame` through the Solvers module which imports `DataFrames`.

**2. Integrate nodal LMP extraction into solve_model!()** (`src/solvers/solver_interface.jl`):

In `solve_model!()` (around line 697, after `_write_log_summary` and before `return result`), add a block that attempts nodal LMP extraction when the system has network data:

```julia
# Auto-extract nodal LMPs when network data is available
if has_solution(result) && !isempty(system.buses) && (!isempty(system.ac_lines) || !isempty(system.dc_lines))
    try
        if progress_callback !== nothing
            progress_callback("Extracting nodal LMPs via DC-OPF...")
        end
        # Use LP result for pricing if available (two-stage), otherwise main result
        pricing_result = result.lp_result !== nothing ? result.lp_result : result
        nodal_df = get_nodal_lmp_dataframe(pricing_result, system)
        if !isempty(nodal_df)
            result.nodal_lmps = nodal_df
            @info "Nodal LMPs extracted" num_buses=length(unique(nodal_df.bus_id)) num_periods=length(unique(nodal_df.period))
        else
            @debug "Nodal LMP extraction returned empty DataFrame (PowerModels may not be available)"
        end
    catch e
        @warn "Nodal LMP extraction failed, zonal PLD still available" exception=e
    end
end
```

This uses the existing `get_nodal_lmp_dataframe()` from solution_extraction.jl. The try/catch ensures the main solve pipeline never breaks due to nodal LMP issues. Uses `has_solution(result)` guard from solver_types.jl.

**3. Add unified pricing function** (`src/solvers/solution_extraction.jl`):

Keep `get_pld_dataframe()` unchanged (it returns submarket-level PLD and works as-is). Add a NEW function `get_pricing_dataframe()` after `get_pld_dataframe()` (after line 710) that provides unified pricing with nodal-first, zonal-fallback logic. This function takes both `result` and `system` (unlike `get_pld_dataframe` which only takes `result`):

```julia
"""
    get_pricing_dataframe(result, system; level=:auto, submarkets=nothing, time_periods=nothing) -> DataFrame

Unified pricing extraction: tries nodal LMPs first, falls back to zonal PLD.

# Arguments
- `result::SolverResult`: Solver result (with optional nodal_lmps from solve_model!)
- `system::ElectricitySystem`: System with bus/submarket mapping for enrichment
- `level::Symbol`: `:nodal` (bus-level), `:zonal` (submarket), or `:auto` (nodal if available, else zonal)
- `submarkets::Union{Vector{String},Nothing}`: Filter by submarket codes
- `time_periods::Union{UnitRange{Int},Nothing}`: Filter by time periods

# Returns
- `DataFrame`: Columns depend on pricing level:
  - Nodal: bus_id, bus_name, submarket, period, lmp
  - Zonal: submarket, period, pld

# Notes
- With `:auto`, returns nodal DataFrame enriched with submarket mapping when nodal_lmps available
- Falls back to get_pld_dataframe() when nodal LMPs not available or empty
- Submarket mapping derived from plant bus_id -> submarket_id assignments
"""
function get_pricing_dataframe(
    result::SolverResult,
    system::ElectricitySystem;
    level::Symbol = :auto,
    submarkets::Union{Vector{String},Nothing} = nothing,
    time_periods::Union{UnitRange{Int},Nothing} = nothing,
)
    use_nodal = level == :nodal || (level == :auto && result.nodal_lmps !== nothing && !isempty(result.nodal_lmps))

    if use_nodal && result.nodal_lmps !== nothing && !isempty(result.nodal_lmps)
        df = copy(result.nodal_lmps)

        # Enrich with submarket info by mapping bus_id -> submarket via plants
        bus_submarket = Dict{String,String}()
        for plant in system.thermal_plants
            if !isempty(plant.bus_id) && !isempty(plant.submarket_id)
                bus_submarket[plant.bus_id] = plant.submarket_id
            end
        end
        for plant in system.hydro_plants
            if !isempty(plant.bus_id) && !isempty(plant.submarket_id)
                bus_submarket[plant.bus_id] = plant.submarket_id
            end
        end

        # Add submarket column
        df.submarket = [get(bus_submarket, bid, "unknown") for bid in df.bus_id]

        # Apply filters
        if submarkets !== nothing
            df = filter(row -> row.submarket in submarkets, df)
        end
        if time_periods !== nothing
            df = filter(row -> row.period in time_periods, df)
        end

        sort!(df, [:period, :bus_id])
        return df
    end

    # Fallback to zonal PLD
    return get_pld_dataframe(result; submarkets = submarkets, time_periods = time_periods)
end
```

Export `get_pricing_dataframe` from `src/solvers/Solvers.jl` by adding it to the export list (after `get_nodal_lmp_dataframe` on line 135).

**4. Add nodal LMPs to CSV export** (`src/analysis/solution_exporter.jl`):

In `export_csv()` (around line 176, after the submarket LMPs block and before the summary block at line 178), add:

```julia
# Export nodal LMPs (if available)
if result.nodal_lmps !== nothing && !isempty(result.nodal_lmps)
    filepath_nodal = joinpath(path, "nodal_lmps.csv")
    CSV.write(filepath_nodal, result.nodal_lmps)
    push!(created_files, filepath_nodal)
end
```

**5. Add nodal LMPs to JSON export** (`src/analysis/solution_exporter.jl`):

In `export_json()` (around line 284, after the dual_values block and before the statistics block at line 287), add:

```julia
# Nodal LMPs (if available)
if result.nodal_lmps !== nothing && !isempty(result.nodal_lmps)
    nodal_dict = Dict{String,Any}()
    for row in eachrow(result.nodal_lmps)
        bus_key = row.bus_id
        if !haskey(nodal_dict, bus_key)
            nodal_dict[bus_key] = Dict{String,Any}(
                "bus_name" => row.bus_name,
                "lmps" => Dict{Int,Float64}(),
            )
        end
        nodal_dict[bus_key]["lmps"][row.period] = row.lmp
    end
    json_data["nodal_lmps"] = nodal_dict
end
```

**6. Run JuliaFormatter** on all modified files:
```bash
julia --project=formattools -e 'using JuliaFormatter; format("src/solvers/solver_types.jl"); format("src/solvers/solver_interface.jl"); format("src/solvers/solution_extraction.jl"); format("src/solvers/Solvers.jl"); format("src/analysis/solution_exporter.jl")'
```

**7. Run full test suite** to confirm no regressions:
```bash
julia --project=test test/runtests.jl
```
All 2061+ existing tests must still pass.
  </action>
  <verify>
Run `julia --project=test test/runtests.jl` -- all 2061+ existing tests pass with zero new failures.

Verify structurally:
- `grep "nodal_lmps" src/solvers/solver_types.jl` shows field in SolverResult
- `grep "get_nodal_lmp_dataframe" src/solvers/solver_interface.jl` shows auto-call in solve_model!
- `grep "get_pricing_dataframe" src/solvers/Solvers.jl` shows new export
- `grep "nodal_lmps" src/analysis/solution_exporter.jl` shows CSV and JSON export blocks
  </verify>
  <done>
SolverResult has nodal_lmps field. solve_model!() auto-extracts nodal LMPs when network data present (graceful failure). get_pricing_dataframe() provides unified pricing (nodal first, zonal fallback). export_csv/export_json include nodal LMPs when available. All 2061+ existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for nodal LMP pipeline integration</name>
  <files>
    test/unit/test_solution_extraction.jl
    test/unit/test_solution_exporter.jl
  </files>
  <action>
**1. Add tests in `test/unit/test_solution_extraction.jl`:**

Add `get_pricing_dataframe` to the import list at the top (around line 24-40, in the `using OpenDESSEM.Solvers:` block).

Add a new `@testset "Nodal LMP Pipeline Integration"` block inside the outer "Solution Extraction" testset, after the existing "Nodal LMP Extraction" testset. Include these test cases:

a) **SolverResult nodal_lmps field exists and defaults to nothing:**
```julia
@testset "SolverResult nodal_lmps field" begin
    result = SolverResult()
    @test result.nodal_lmps === nothing

    # Can set to a DataFrame
    df = DataFrame(bus_id=["B1"], bus_name=["Bus 1"], period=[1], lmp=[50.0])
    result.nodal_lmps = df
    @test result.nodal_lmps !== nothing
    @test nrow(result.nodal_lmps) == 1
end
```

b) **get_pricing_dataframe falls back to zonal when no nodal LMPs present:**

Create a SolverResult with submarket duals but nodal_lmps=nothing. Create a minimal ElectricitySystem (reuse create_small_test_system and extract only the system, or build one manually with the entity constructors already imported). Call `get_pricing_dataframe(result, system)`. Assert the returned DataFrame has columns `submarket` and `pld` (zonal format), not `bus_id`.

c) **get_pricing_dataframe returns nodal data when nodal_lmps is populated:**

Create a SolverResult with both nodal_lmps DataFrame and submarket duals. Call `get_pricing_dataframe(result, system)`. Assert the returned DataFrame has `bus_id` and `lmp` columns (nodal format). Assert row count matches nodal data. Assert `submarket` column is added (enrichment).

d) **get_pricing_dataframe with level=:zonal forces zonal even when nodal available:**

Create result with nodal_lmps and duals. Call `get_pricing_dataframe(result, system; level=:zonal)`. Assert result has `submarket`/`pld` columns and does NOT have `bus_id`.

e) **get_pricing_dataframe with submarket and time_period filters:**

Create result with nodal_lmps spanning 2 periods and 2 buses. Filter by time_periods=1:1. Assert only period 1 rows returned.

For the `system` argument in these tests, use either `create_small_test_system()` (returns model, system tuple -- use the system) or build a minimal ElectricitySystem with the entity constructors already available in the test imports. The system needs thermal_plants with bus_id and submarket_id set so the bus->submarket mapping works.

**2. Add tests in `test/unit/test_solution_exporter.jl`:**

Add `DataFrame` to imports if not already present (it is -- line 15).

Add three new testsets inside the outer "Solution Exporter" testset:

a) **export_csv includes nodal LMPs when present:**
```julia
@testset "export_csv includes nodal LMPs" begin
    model, system = create_small_test_system()
    result = solve_model!(model, system; pricing = true)

    # Manually set nodal_lmps to simulate available data
    result.nodal_lmps = DataFrame(
        bus_id = ["B1", "B2"],
        bus_name = ["Bus 1", "Bus 2"],
        period = [1, 1],
        lmp = [50.0, 55.0],
    )

    mktempdir() do tmpdir
        files = export_csv(result, tmpdir; time_periods = 1:6)
        nodal_file = joinpath(tmpdir, "nodal_lmps.csv")
        @test isfile(nodal_file)
        df = CSV.read(nodal_file, DataFrame)
        @test "bus_id" in names(df)
        @test "lmp" in names(df)
        @test nrow(df) == 2
    end
end
```

b) **export_json includes nodal LMPs section:**
```julia
@testset "export_json includes nodal LMPs" begin
    model, system = create_small_test_system()
    result = solve_model!(model, system; pricing = true)

    result.nodal_lmps = DataFrame(
        bus_id = ["B1", "B2"],
        bus_name = ["Bus 1", "Bus 2"],
        period = [1, 1],
        lmp = [50.0, 55.0],
    )

    mktempdir() do tmpdir
        filepath = joinpath(tmpdir, "solution.json")
        export_json(result, filepath; time_periods = 1:6)
        @test isfile(filepath)
        content = read(filepath, String)
        @test contains(content, "nodal_lmps")
        @test contains(content, "B1")
    end
end
```

c) **export_csv omits nodal file when nodal_lmps is nothing:**
```julia
@testset "export_csv without nodal LMPs omits nodal file" begin
    model, system = create_small_test_system()
    result = solve_model!(model, system; pricing = true)
    # nodal_lmps is nothing by default

    mktempdir() do tmpdir
        files = export_csv(result, tmpdir; time_periods = 1:6)
        nodal_file = joinpath(tmpdir, "nodal_lmps.csv")
        @test !isfile(nodal_file)
    end
end
```

**3. Run JuliaFormatter** on test files:
```bash
julia --project=formattools -e 'using JuliaFormatter; format("test/unit/test_solution_extraction.jl"); format("test/unit/test_solution_exporter.jl")'
```

**4. Run full test suite:**
```bash
julia --project=test test/runtests.jl
```
All tests (existing 2061+ plus new ~15-18) must pass.
  </action>
  <verify>
Run `julia --project=test test/runtests.jl` -- all tests pass including new ones.

Count new test assertions: `grep -c "@test" test/unit/test_solution_extraction.jl` and `grep -c "@test" test/unit/test_solution_exporter.jl` should each show increases over pre-plan counts.
  </verify>
  <done>
New tests verify: (1) SolverResult.nodal_lmps field exists and defaults to nothing, (2) get_pricing_dataframe returns nodal when available and falls back to zonal, (3) level=:zonal forces zonal pricing, (4) filters work on nodal data, (5) export_csv creates nodal_lmps.csv when data present and omits it otherwise, (6) export_json includes nodal_lmps section. All 2075+ tests pass.
  </done>
</task>

</tasks>

<verification>
1. `julia --project=test test/runtests.jl` -- all tests pass (existing + new)
2. `grep "nodal_lmps" src/solvers/solver_types.jl` -- field exists in SolverResult
3. `grep "get_nodal_lmp_dataframe" src/solvers/solver_interface.jl` -- auto-extraction in solve_model!
4. `grep "get_pricing_dataframe" src/solvers/solution_extraction.jl` -- unified pricing function exists
5. `grep "nodal_lmps" src/analysis/solution_exporter.jl` -- CSV and JSON export blocks
6. `grep "get_pricing_dataframe" src/solvers/Solvers.jl` -- exported from module
</verification>

<success_criteria>
- SolverResult.nodal_lmps stores DataFrame (or nothing) without recomputation
- solve_model!() auto-attempts nodal LMP extraction after solve when system has buses+lines
- Nodal LMP failure never breaks the solve pipeline (try/catch with @warn)
- get_pricing_dataframe() returns nodal (enriched with submarket) when available, zonal PLD otherwise
- export_csv() creates nodal_lmps.csv when nodal data present
- export_json() includes nodal_lmps section when nodal data present
- All 2061+ existing tests still pass, plus ~15 new test assertions
</success_criteria>

<output>
After completion, create `.planning/phases/04-solution-extraction-export/04-04-SUMMARY.md`
</output>
