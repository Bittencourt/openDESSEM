---
phase: 04-solution-extraction-export
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/solvers/solution_extraction.jl
  - src/analysis/solution_exporter.jl
  - test/unit/test_solution_extraction.jl
  - test/unit/test_solution_exporter.jl
  - test/runtests.jl
autonomous: true

must_haves:
  truths:
    - "All primal variable values extract correctly including deficit variables"
    - "PLD marginal prices extract per submarket per time period"
    - "CSV export produces readable dispatch and price files with entity identifiers"
    - "JSON export produces valid nested JSON structure with pretty printing"
  artifacts:
    - path: "src/solvers/solution_extraction.jl"
      provides: "Deficit variable extraction in extract_solution_values!()"
      contains: "deficit"
    - path: "src/analysis/solution_exporter.jl"
      provides: "Fixed JSON3.pretty usage in export_json()"
      contains: "JSON3.pretty"
    - path: "test/unit/test_solution_extraction.jl"
      provides: "Unit tests for all extraction functions"
      min_lines: 100
    - path: "test/unit/test_solution_exporter.jl"
      provides: "Unit tests for CSV and JSON export"
      min_lines: 100
  key_links:
    - from: "src/solvers/solution_extraction.jl"
      to: "result.variables[:deficit]"
      via: "extract_solution_values! populating deficit dict"
      pattern: "result\\.variables\\[:deficit\\]"
    - from: "src/analysis/solution_exporter.jl"
      to: "JSON3.pretty(io, ...)"
      via: "two-argument form of JSON3.pretty writing to IO"
      pattern: "JSON3\\.pretty\\(io"
---

<objective>
Complete solution extraction and export by filling two concrete gaps (deficit variable extraction and JSON3.pretty bug) and adding thorough unit tests for the extraction and export code paths.

Purpose: EXTR-01 requires all variable types including deficit. EXTR-03/EXTR-04 require working CSV and JSON export. These were partially built in Phase 3 but have gaps and no dedicated unit tests.

Output: Fixed extraction and export code with comprehensive test coverage confirming all extraction (EXTR-01, EXTR-02) and export (EXTR-03, EXTR-04) paths work correctly.
</objective>

<execution_context>
@/home/pedro/.claude/get-shit-done/workflows/execute-plan.md
@/home/pedro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-solution-extraction-export/04-RESEARCH.md
@src/solvers/solution_extraction.jl
@src/analysis/solution_exporter.jl
@src/solvers/Solvers.jl
@src/analysis/Analysis.jl
@test/fixtures/small_system.jl
@test/integration/test_solver_end_to_end.jl
@src/variables/variable_manager.jl
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add deficit extraction and fix JSON3.pretty bug</name>
  <files>
    src/solvers/solution_extraction.jl
    src/analysis/solution_exporter.jl
  </files>
  <action>
**1. Add deficit variable extraction to `extract_solution_values!()` in `src/solvers/solution_extraction.jl`:**

After the renewable curtailment extraction block (line ~256, before `result.has_values = true`), add a deficit variable extraction block following the exact same pattern as existing extractions:

```julia
# Extract deficit variables
if haskey(model, :deficit)
    deficit = model[:deficit]
    deficit_values = Dict{Tuple{String,Int},Float64}()
    submarket_indices = get_submarket_indices(system)
    for submarket in system.submarkets
        if haskey(submarket_indices, submarket.code)
            idx = submarket_indices[submarket.code]
            for t in time_periods
                try
                    val = value(deficit[idx, t])
                    deficit_values[(submarket.code, t)] = val
                catch
                    @warn "Could not extract deficit value for deficit[$idx, $t]"
                end
            end
        end
    end
    result.variables[:deficit] = deficit_values
end
```

Key details:
- Deficit variables are indexed by `(integer_submarket_index, time_period)` in the JuMP model (created by `create_deficit_variables!()` in variable_manager.jl)
- Use `get_submarket_indices(system)` to map submarket codes to integer indices
- Store in result as `Dict{Tuple{String,Int},Float64}` keyed by `(submarket_code, time_period)` to match how `get_cost_breakdown()` expects it
- `get_submarket_indices` is already imported in the Solvers module via `using ..OpenDESSEM.Variables: get_thermal_plant_indices, get_hydro_plant_indices, get_renewable_plant_indices` -- add `get_submarket_indices` to this import if not already there

Check the import line in `src/solvers/Solvers.jl` (line ~69). It currently imports `get_thermal_plant_indices, get_hydro_plant_indices, get_renewable_plant_indices`. Add `get_submarket_indices` to this import list.

Also update the docstring of `extract_solution_values!()` to include `:deficit` in the Variables Extracted section:
```
- `:deficit`: Dict[(submarket_code, t) => value_mw]
```

**2. Fix JSON3.pretty bug in `export_json()` in `src/analysis/solution_exporter.jl`:**

Replace lines 293-300 (the `if pretty` block) with:

```julia
if pretty
    open(filepath, "w") do io
        JSON3.pretty(io, JSON3.write(json_data))
    end
else
    open(filepath, "w") do io
        JSON3.write(io, json_data)
    end
end
```

The bug: the old code called `JSON3.write(io, json_data)` then re-read the file, called `JSON3.pretty(content)` which prints to stdout and returns `nothing`, then wrote `nothing` to the file. The fix uses the two-argument form `JSON3.pretty(io, json_string)` which writes pretty JSON directly to the IO stream.
  </action>
  <verify>
Run the existing test suite to ensure nothing broke:
```bash
julia --project=test test/runtests.jl
```
All existing tests should pass. The deficit extraction and JSON fix are additive changes.
  </verify>
  <done>
- `extract_solution_values!()` extracts deficit variables keyed by `(submarket_code, t)`
- `get_submarket_indices` is properly imported in the Solvers module
- `export_json()` uses `JSON3.pretty(io, JSON3.write(json_data))` two-argument form
- All existing tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Add unit tests for extraction and export</name>
  <files>
    test/unit/test_solution_extraction.jl
    test/unit/test_solution_exporter.jl
    test/runtests.jl
  </files>
  <action>
**1. Create `test/unit/test_solution_extraction.jl`:**

Create a comprehensive test file that tests all solution extraction functions. The test strategy is to create a small test system using the factory, solve it, then verify extraction results.

Structure the test file as:

```julia
using Test
using JuMP
using HiGHS
using Dates
using DataFrames

using OpenDESSEM
using OpenDESSEM.Solvers

# Include small system factory
include(joinpath(@__DIR__, "..", "fixtures", "small_system.jl"))
using .SmallSystemFactory: create_small_test_system

@testset "Solution Extraction" begin

    @testset "extract_solution_values! - all variable types" begin
        model, system = create_small_test_system(; include_deficit=true)
        result = solve_model!(model, system; pricing=false)

        # Thermal generation extracted
        @test haskey(result.variables, :thermal_generation)
        @test !isempty(result.variables[:thermal_generation])
        # Values are non-negative
        @test all(v >= -1e-6 for v in values(result.variables[:thermal_generation]))

        # Thermal commitment extracted
        @test haskey(result.variables, :thermal_commitment)

        # Thermal startup extracted
        @test haskey(result.variables, :thermal_startup)

        # Thermal shutdown extracted
        @test haskey(result.variables, :thermal_shutdown)

        # Hydro generation extracted
        @test haskey(result.variables, :hydro_generation)

        # Hydro storage extracted
        @test haskey(result.variables, :hydro_storage)

        # Hydro outflow extracted
        @test haskey(result.variables, :hydro_outflow)

        # Deficit extracted (NEW - Phase 4 gap closure)
        @test haskey(result.variables, :deficit)
        @test !isempty(result.variables[:deficit])
        # Deficit keyed by (submarket_code, t)
        first_key = first(keys(result.variables[:deficit]))
        @test first_key isa Tuple{String, Int}
        @test first_key[1] == "SE"  # Only submarket in test system
    end

    @testset "extract_solution_values! - deficit values are consistent" begin
        model, system = create_small_test_system(; include_deficit=true)
        result = solve_model!(model, system; pricing=false)

        if haskey(result.variables, :deficit)
            deficit = result.variables[:deficit]
            # All deficit values >= 0 (non-negative constraint)
            @test all(v >= -1e-6 for v in values(deficit))
            # Correct number of entries: 1 submarket * 6 periods
            @test length(deficit) == 6
        end
    end

    @testset "get_thermal_generation returns correct vector" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        gen = get_thermal_generation(result, "T001", 1:6)
        @test length(gen) == 6
        @test all(g >= 0 for g in gen)
    end

    @testset "get_hydro_generation returns correct vector" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        gen = get_hydro_generation(result, "H001", 1:6)
        @test length(gen) == 6
        @test all(g >= 0 for g in gen)
    end

    @testset "get_hydro_storage returns correct vector" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        storage = get_hydro_storage(result, "H001", 1:6)
        @test length(storage) == 6
        @test all(s >= 0 for s in storage)
    end

    @testset "get_pld_dataframe with two-stage pricing" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=true)

        # Use LP result for PLDs
        lp_result = result.lp_result
        if lp_result !== nothing && lp_result.has_duals
            pld_df = get_pld_dataframe(lp_result)
            @test pld_df isa DataFrame
            @test "submarket" in names(pld_df)
            @test "period" in names(pld_df)
            @test "pld" in names(pld_df)
            if nrow(pld_df) > 0
                @test all(pld_df.submarket .== "SE")
            end
        end
    end

    @testset "get_pld_dataframe filtering" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=true)

        lp_result = result.lp_result
        if lp_result !== nothing && lp_result.has_duals
            # Filter by submarket
            pld_se = get_pld_dataframe(lp_result; submarkets=["SE"])
            @test all(pld_se.submarket .== "SE")

            # Filter by time period
            pld_peak = get_pld_dataframe(lp_result; time_periods=4:6)
            if nrow(pld_peak) > 0
                @test all(pld_peak.period .>= 4)
                @test all(pld_peak.period .<= 6)
            end
        end
    end

    @testset "get_cost_breakdown returns CostBreakdown" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        breakdown = get_cost_breakdown(result, system)
        @test breakdown isa CostBreakdown
        @test breakdown.total >= 0
        @test breakdown.thermal_fuel >= 0
        @test breakdown.total == breakdown.thermal_fuel + breakdown.thermal_startup +
            breakdown.thermal_shutdown + breakdown.deficit_penalty + breakdown.hydro_water_value
    end

    @testset "get_submarket_lmps returns vector" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=true)

        lp_result = result.lp_result
        if lp_result !== nothing && lp_result.has_duals
            lmps = get_submarket_lmps(lp_result, "SE", 1:6)
            @test length(lmps) == 6
            @test lmps isa Vector{Float64}
        end
    end

    @testset "Missing data returns zeros/warnings gracefully" begin
        # Create result without values
        result = SolverResult()
        gen = get_thermal_generation(result, "T_FAKE", 1:6)
        @test length(gen) == 6
        @test all(gen .== 0.0)

        lmps = get_submarket_lmps(result, "SE", 1:6)
        @test length(lmps) == 6
        @test all(lmps .== 0.0)
    end
end
```

**2. Create `test/unit/test_solution_exporter.jl`:**

Test CSV and JSON export functionality using temporary directories.

```julia
using Test
using JuMP
using HiGHS
using Dates
using DataFrames
using CSV
using JSON3

using OpenDESSEM
using OpenDESSEM.Solvers
using OpenDESSEM.Analysis

# Include small system factory
include(joinpath(@__DIR__, "..", "fixtures", "small_system.jl"))
using .SmallSystemFactory: create_small_test_system

@testset "Solution Exporter" begin

    @testset "export_csv creates expected files" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=true)

        # Use temporary directory
        mktempdir() do tmpdir
            files = export_csv(result, tmpdir; time_periods=1:6)

            @test length(files) > 0
            @test all(isfile, files)

            # Check thermal generation CSV exists and has correct structure
            thermal_file = joinpath(tmpdir, "thermal_generation.csv")
            if isfile(thermal_file)
                df = CSV.read(thermal_file, DataFrame)
                @test "plant_id" in names(df)
                @test nrow(df) >= 1  # At least 1 thermal plant
                # Check time period columns exist
                @test "t_1" in names(df)
                @test "t_6" in names(df)
            end

            # Check summary CSV exists
            summary_file = joinpath(tmpdir, "summary.csv")
            @test isfile(summary_file)
            summary_df = CSV.read(summary_file, DataFrame)
            @test nrow(summary_df) > 0
        end
    end

    @testset "export_csv includes hydro files" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        mktempdir() do tmpdir
            files = export_csv(result, tmpdir; time_periods=1:6)

            hydro_gen = joinpath(tmpdir, "hydro_generation.csv")
            hydro_stor = joinpath(tmpdir, "hydro_storage.csv")

            @test isfile(hydro_gen)
            @test isfile(hydro_stor)

            if isfile(hydro_gen)
                df = CSV.read(hydro_gen, DataFrame)
                @test "plant_id" in names(df)
                @test nrow(df) >= 1
            end
        end
    end

    @testset "export_csv with LMP data" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=true)

        # Use LP result for duals
        export_result = result.lp_result !== nothing ? result.lp_result : result

        if export_result.has_duals
            mktempdir() do tmpdir
                files = export_csv(export_result, tmpdir; time_periods=1:6)
                lmp_file = joinpath(tmpdir, "submarket_lmps.csv")
                @test isfile(lmp_file)

                if isfile(lmp_file)
                    df = CSV.read(lmp_file, DataFrame)
                    @test "submarket_id" in names(df)
                end
            end
        end
    end

    @testset "export_json creates valid JSON file" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        mktempdir() do tmpdir
            filepath = joinpath(tmpdir, "solution.json")
            returned_path = export_json(result, filepath; time_periods=1:6, pretty=true)

            @test isfile(filepath)
            @test returned_path == abspath(filepath)

            # Read and parse the JSON
            content = read(filepath, String)
            @test length(content) > 10  # Not empty or "nothing"
            @test content != "nothing"  # Verify JSON3.pretty bug is fixed

            # Parse JSON and verify structure
            json = JSON3.read(content)
            @test haskey(json, :metadata) || haskey(json, "metadata")
            @test haskey(json, :solution) || haskey(json, "solution")
            @test haskey(json, :variables) || haskey(json, "variables")
        end
    end

    @testset "export_json with pretty=false" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        mktempdir() do tmpdir
            filepath = joinpath(tmpdir, "solution_compact.json")
            export_json(result, filepath; time_periods=1:6, pretty=false)

            @test isfile(filepath)
            content = read(filepath, String)
            @test length(content) > 10
            @test content != "nothing"

            # Should be parseable JSON
            json = JSON3.read(content)
            @test haskey(json, :metadata) || haskey(json, "metadata")
        end
    end

    @testset "export_json contains thermal generation data" begin
        model, system = create_small_test_system()
        result = solve_model!(model, system; pricing=false)

        mktempdir() do tmpdir
            filepath = joinpath(tmpdir, "solution.json")
            export_json(result, filepath; time_periods=1:6, pretty=true)

            content = read(filepath, String)
            json = JSON3.read(content)

            # Check variables section has thermal generation
            vars = get(json, :variables, get(json, "variables", nothing))
            @test vars !== nothing
            if vars !== nothing
                tg = get(vars, :thermal_generation, get(vars, "thermal_generation", nothing))
                @test tg !== nothing
            end
        end
    end

    @testset "export_csv errors on result without values" begin
        result = SolverResult()
        mktempdir() do tmpdir
            @test_throws ErrorException export_csv(result, tmpdir)
        end
    end

    @testset "export_json errors on result without values" begin
        result = SolverResult()
        mktempdir() do tmpdir
            filepath = joinpath(tmpdir, "fail.json")
            @test_throws ErrorException export_json(result, filepath)
        end
    end
end
```

**3. Update `test/runtests.jl`:**

Add includes for the two new test files. Find the existing include section and add:

```julia
include("unit/test_solution_extraction.jl")
include("unit/test_solution_exporter.jl")
```

Place these after the existing unit test includes (after `test_solver_interface.jl` or similar).
  </action>
  <verify>
Run the full test suite including the new tests:
```bash
julia --project=test test/runtests.jl
```
All tests should pass. Specifically verify:
- `test_solution_extraction.jl` tests pass (deficit extraction, PLD extraction, cost breakdown)
- `test_solution_exporter.jl` tests pass (CSV files created, JSON is valid and not "nothing")
- JSON export test explicitly checks `content != "nothing"` to confirm the JSON3.pretty bug fix
  </verify>
  <done>
- `test/unit/test_solution_extraction.jl` exists with tests for all variable types including deficit, PLD extraction, cost breakdown, and graceful degradation
- `test/unit/test_solution_exporter.jl` exists with tests for CSV export (file creation, column headers, data), JSON export (valid JSON, not "nothing", correct structure), and error handling
- Both test files are included in `test/runtests.jl`
- All tests pass including the new ones
  </done>
</task>

</tasks>

<verification>
Run the full test suite:
```bash
julia --project=test test/runtests.jl
```

All tests pass. Specifically:
1. Deficit variables are extracted by `extract_solution_values!()` keyed by `(submarket_code, t)`
2. `get_cost_breakdown()` can now read deficit values from the result (previously always 0 due to missing extraction)
3. CSV export creates files with correct column headers and entity identifiers
4. JSON export produces valid JSON (not "nothing") with nested structure containing metadata, solution, variables, and dual_values
5. PLD DataFrame output has correct columns (submarket, period, pld)
</verification>

<success_criteria>
- EXTR-01: All variable types extract (thermal dispatch/commitment, hydro storage/outflow/generation, renewable generation/curtailment, deficit) -- verified by test_solution_extraction.jl
- EXTR-02: PLD marginal prices extract per submarket per time period from LP relaxation -- verified by get_pld_dataframe and get_submarket_lmps tests
- EXTR-03: CSV export creates readable files with entity identifiers and time period columns -- verified by test_solution_exporter.jl CSV tests
- EXTR-04: JSON export produces valid nested JSON (not "nothing") -- verified by test_solution_exporter.jl JSON tests checking content != "nothing"
</success_criteria>

<output>
After completion, create `.planning/phases/04-solution-extraction-export/04-01-SUMMARY.md`
</output>
