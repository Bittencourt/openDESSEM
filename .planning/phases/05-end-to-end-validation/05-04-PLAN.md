---
phase: 05-end-to-end-validation
plan: 04
type: execute
wave: 3
depends_on: ["05-03"]
files_modified:
  - scripts/extract_reference_data.jl
  - docs/Sample/DS_ONS_102025_RV2D11/expected/total_cost.csv
  - docs/Sample/DS_ONS_102025_RV2D11/expected/pld_by_submarket.csv
  - docs/Sample/DS_ONS_102025_RV2D11/expected/thermal_dispatch.csv
  - docs/Sample/DS_ONS_102025_RV2D11/expected/hydro_dispatch.csv
  - docs/Sample/DS_ONS_102025_RV2D11/expected/hydro_storage.csv
  - test/integration/test_end_to_end_validation.jl
  - test/runtests.jl
autonomous: true

must_haves:
  truths:
    - "Reference CSV files extracted from PDO files in expected/ directory with correct schemas"
    - "Integration test loads ONS sample data DS_ONS_102025_RV2D11, solves model, and extracts results without errors"
    - "Integration test runs validate_against_reference() and produces ValidationResult"
    - "Validation report generated in all three formats (console, markdown, JSON)"
    - "Total cost comparison executes with 5% tolerance (pass or fail with diagnostics)"
    - "PLD comparison executes with pass-rate threshold approach (pass or fail with diagnostics)"
  artifacts:
    - path: "scripts/extract_reference_data.jl"
      provides: "One-time PDO file parser that creates reference CSVs"
      contains: "function extract_reference"
    - path: "docs/Sample/DS_ONS_102025_RV2D11/expected/pld_by_submarket.csv"
      provides: "Reference PLD data with period,submarket,pld_rs_per_mwh columns"
      contains: "period,submarket,pld_rs_per_mwh"
    - path: "docs/Sample/DS_ONS_102025_RV2D11/expected/thermal_dispatch.csv"
      provides: "Reference thermal dispatch with period,plant_id,generation_mw columns"
      contains: "period,plant_id,generation_mw"
    - path: "test/integration/test_end_to_end_validation.jl"
      provides: "End-to-end validation integration test"
      min_lines: 60
  key_links:
    - from: "scripts/extract_reference_data.jl"
      to: "docs/Sample/DS_ONS_102025_RV2D11/pdo_cmosist.dat"
      via: "Parses semicolon-delimited PDO output format"
      pattern: "pdo_cmosist"
    - from: "test/integration/test_end_to_end_validation.jl"
      to: "src/validation/Validation.jl"
      via: "Uses validate_against_reference() and report_validation()"
      pattern: "validate_against_reference"
    - from: "test/integration/test_end_to_end_validation.jl"
      to: "docs/Sample/DS_ONS_102025_RV2D11/"
      via: "Loads ONS sample data via DessemLoader"
      pattern: "DS_ONS_102025_RV2D11"
---

<objective>
Extract reference data from PDO files and create the end-to-end integration test that validates OpenDESSEM against official DESSEM results.

Purpose: This is the capstone plan. It creates the actual reference data from ONS sample PDO files and the integration test that proves OpenDESSEM produces correct results. Without this, Phases 1-4 remain unvalidated against real data.

Output:
- `scripts/extract_reference_data.jl` - One-time extraction script parsing PDO files into reference CSVs
- `docs/Sample/DS_ONS_102025_RV2D11/expected/*.csv` - Five reference CSV files
- `test/integration/test_end_to_end_validation.jl` - Full end-to-end validation integration test
- Validation report generated proving OpenDESSEM results vs official DESSEM
</objective>

<execution_context>
@/home/pedro/.claude/get-shit-done/workflows/execute-plan.md
@/home/pedro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-end-to-end-validation/05-CONTEXT.md
@.planning/phases/05-end-to-end-validation/05-RESEARCH.md
@.planning/phases/05-end-to-end-validation/05-01-SUMMARY.md (types and loaders)
@.planning/phases/05-end-to-end-validation/05-02-SUMMARY.md (comparators)
@.planning/phases/05-end-to-end-validation/05-03-SUMMARY.md (reporters and module wiring)
@docs/Sample/DS_ONS_102025_RV2D11/pdo_cmosist.dat (PLD reference format)
@docs/Sample/DS_ONS_102025_RV2D11/pdo_term.dat (thermal dispatch format, first 50 lines)
@docs/Sample/DS_ONS_102025_RV2D11/pdo_hidr.dat (hydro dispatch format, first 50 lines)
@test/integration/test_solver_end_to_end.jl (pattern: end-to-end test structure)
@test/fixtures/small_system.jl (pattern: test system factory)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PDO extraction script and generate reference CSVs</name>
  <files>
    scripts/extract_reference_data.jl
    docs/Sample/DS_ONS_102025_RV2D11/expected/total_cost.csv
    docs/Sample/DS_ONS_102025_RV2D11/expected/pld_by_submarket.csv
    docs/Sample/DS_ONS_102025_RV2D11/expected/thermal_dispatch.csv
    docs/Sample/DS_ONS_102025_RV2D11/expected/hydro_dispatch.csv
    docs/Sample/DS_ONS_102025_RV2D11/expected/hydro_storage.csv
  </files>
  <action>
**Create `scripts/extract_reference_data.jl`:**

A standalone Julia script that parses DESSEM PDO output files and generates reference CSV files. This is a one-time utility, not part of the Validation module.

The script should:

1. **Parse `pdo_cmosist.dat`** (PLD reference):
   - Format: semicolon-delimited with padding, header lines start with `-`
   - Columns: IPER, Pat, SIST, Cmarg, PI_Demanda
   - Extract: period (IPER), submarket (SIST), pld_rs_per_mwh (Cmarg)
   - Skip header/separator lines (lines starting with `-` or containing column names)
   - Output: `pld_by_submarket.csv` with columns `period,submarket,pld_rs_per_mwh`

2. **Parse `pdo_term.dat`** (thermal dispatch reference):
   - Format: semicolon-delimited
   - Columns: IPER, Pat, USIT, Nome, Unid, Sist, Geracao, GMin, GMax, Capacidade, L/D, CustoLinear
   - **Important:** Filter to Unid=99 rows only (plant-level summary, not individual units)
   - Extract: period (IPER), plant_id (USIT as string), generation_mw (Geracao)
   - Output: `thermal_dispatch.csv` with columns `period,plant_id,generation_mw`

3. **Parse `pdo_hidr.dat`** (hydro dispatch and storage reference):
   - Format: semicolon-delimited
   - Read the file header to understand column layout (varies by DESSEM version)
   - Extract generation: period, plant_id (USIH as string), generation_mw
   - Extract storage: period, plant_id (USIH as string), storage_hm3 (volume)
   - Output two files:
     - `hydro_dispatch.csv` with columns `period,plant_id,generation_mw`
     - `hydro_storage.csv` with columns `period,plant_id,storage_hm3`

4. **Total cost:**
   - Look in `des_log_relato.dat` for total cost value, or compute from `pdo_sist.dat` aggregates
   - If total cost cannot be reliably extracted, create `total_cost.csv` with a placeholder value and add a comment in the script explaining how to populate it manually
   - Output: `total_cost.csv` with column `total_cost_rs`

**Run the extraction script:**
```bash
julia scripts/extract_reference_data.jl docs/Sample/DS_ONS_102025_RV2D11/
```

**Verify the generated CSVs:**
- Check that `pld_by_submarket.csv` has 375 rows (75 periods x 5 submarkets)
- Check that `thermal_dispatch.csv` has rows for each thermal plant per period
- Check that `hydro_dispatch.csv` and `hydro_storage.csv` have rows for each hydro plant per period
- Check that column names match expected schemas exactly

**Important notes:**
- Plant IDs in reference CSVs should use the DESSEM numeric codes as strings (e.g., "1", "2", "45") since that's what DessemLoader maps them to. Verify by checking how `convert_dessem_thermal()` in `src/data/loaders/dessem_loader.jl` creates plant IDs.
- The extraction script is a build tool, not part of the validation module. It lives in `scripts/` not `src/`.
  </action>
  <verify>
Run the extraction script and verify output:
```bash
julia scripts/extract_reference_data.jl docs/Sample/DS_ONS_102025_RV2D11/
head -5 docs/Sample/DS_ONS_102025_RV2D11/expected/pld_by_submarket.csv
head -5 docs/Sample/DS_ONS_102025_RV2D11/expected/thermal_dispatch.csv
wc -l docs/Sample/DS_ONS_102025_RV2D11/expected/*.csv
```
PLD CSV has correct header and 375+ data rows. Thermal dispatch has rows for plant-level summaries. All CSVs have correct column schemas.
  </verify>
  <done>
PDO extraction script created and executed. Five reference CSV files generated in expected/ directory with correct schemas: total_cost.csv, pld_by_submarket.csv, thermal_dispatch.csv, hydro_dispatch.csv, hydro_storage.csv. Plant IDs match OpenDESSEM's DessemLoader ID scheme.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create end-to-end validation integration test</name>
  <files>
    test/integration/test_end_to_end_validation.jl
    test/runtests.jl
  </files>
  <action>
**Create `test/integration/test_end_to_end_validation.jl`:**

This is the capstone integration test that proves Phase 5 success criteria. It should:

1. **Test: Load ONS sample data and solve** (VALD-01):
   ```julia
   @testset "End-to-End Validation - ONS DS_ONS_102025_RV2D11" begin
       # Load ONS sample data
       sample_dir = joinpath(@__DIR__, "..", "..", "docs", "Sample", "DS_ONS_102025_RV2D11")
       @test isdir(sample_dir)

       # Load system via DessemLoader
       loader = DessemLoader(sample_dir)
       system = load_system(loader)
       @test !isnothing(system)

       # Build and solve model
       # ... (follow existing end-to-end test pattern from test_solver_end_to_end.jl)
       result = solve_model!(model; pricing=true)
       @test result.status == OPTIMAL || result.status == TIME_LIMIT
   end
   ```

2. **Test: Run validation against reference data** (VALD-02, VALD-03):
   ```julia
   @testset "Validation Against Reference" begin
       reference_dir = joinpath(sample_dir, "expected")
       @test isdir(reference_dir)

       # Run full validation
       vr = validate_against_reference(
           result, system, reference_dir;
           cost_tolerance = 0.05,
           pld_pass_rate = 0.80,
           pld_tolerance = 0.10,
           dispatch_tolerance = 0.10,
       )

       # Test ValidationResult structure
       @test vr isa ValidationResult
       @test vr.timestamp isa DateTime
       @test vr.reference_dir == reference_dir
       @test vr.exit_code isa Int
       @test vr.exit_code >= 0

       # Test that all comparisons ran (no crashes, per CONTEXT.md collect-all behavior)
       @test !isnothing(vr.cost_comparison)
       @test !isnothing(vr.pld_comparison)
       @test length(vr.dispatch_comparisons) > 0

       # Log validation results for visibility (don't assert pass/fail yet - first run is diagnostic)
       println("=== Validation Results ===")
       println("Overall: ", vr.passed ? "PASS" : "FAIL")
       println("Cost: ", vr.cost_passed ? "PASS" : "FAIL")
       println("PLD: ", vr.pld_passed ? "PASS" : "FAIL")
       println("Dispatch: ", vr.dispatch_passed ? "PASS" : "FAIL")
       println("Exit code: ", vr.exit_code)
   end
   ```

3. **Test: Generate validation report** (VALD-04):
   ```julia
   @testset "Validation Report Generation" begin
       mktempdir() do tmpdir
           (md_path, json_path) = report_validation(vr; output_dir=tmpdir)

           # Markdown report exists and has content
           @test isfile(md_path)
           md_content = read(md_path, String)
           @test length(md_content) > 100
           @test occursin("Total Cost", md_content)
           @test occursin("PLD", md_content)

           # JSON report exists and is valid
           @test isfile(json_path)
           json_content = read(json_path, String)
           json_parsed = JSON3.read(json_content)
           @test haskey(json_parsed, :overall_passed)
           @test haskey(json_parsed, :exit_code)
       end
   end
   ```

**Important design note:** The integration test should NOT hard-assert that validation passes (vr.passed == true) because the first run is diagnostic. OpenDESSEM may not match official DESSEM perfectly on the first attempt. Instead, the test asserts that:
- The solve completes without errors (VALD-01)
- The validation pipeline runs to completion (no crashes, all comparisons execute)
- Reports generate correctly (VALD-04)
- Results are logged for human review

If the cost is within 5% and PLDs meet the pass-rate threshold, that's a bonus. The test documents current accuracy without gating on it. Future gap closure plans can tighten assertions once known deviations are understood and addressed.

**However**, DO assert the tolerance checks run with correct parameters, and DO log the actual values for diagnostic purposes. If validation passes, also add a @test for it as a regression guard.

**Update `test/runtests.jl`:**
Add the integration test at the end:
```julia
# End-to-end validation integration test
include("integration/test_end_to_end_validation.jl")
```

**Note on test execution time:** The ONS sample solve may take 1-5 minutes depending on system. If it's too slow for CI, wrap it in an environment variable check: `if get(ENV, "OPENDESEM_FULL_VALIDATION", "false") == "true"`. But try running it first - if it's under 2 minutes, keep it in the regular test suite.
  </action>
  <verify>
Run the integration test:
```bash
julia --project=test -e 'include("test/integration/test_end_to_end_validation.jl")'
```
Test completes without errors. ValidationResult struct populated. Reports generated. Console output shows diagnostic comparison results.

Run full test suite to check for regressions:
```bash
julia --project=test test/runtests.jl
```
All 2075+ existing tests pass. New validation tests pass.
  </verify>
  <done>
End-to-end validation integration test loads ONS sample data, solves the model, runs validate_against_reference(), and generates all three report formats. Test completes without errors. Validation results logged for diagnostic review. Full test suite passes with no regressions.
  </done>
</task>

</tasks>

<verification>
1. Reference CSV files exist in `docs/Sample/DS_ONS_102025_RV2D11/expected/` with correct schemas
2. PLD reference has 375 rows (75 periods x 5 submarkets)
3. Integration test loads ONS sample data without errors (VALD-01)
4. Integration test runs full validation pipeline without crashes
5. Integration test generates all three report formats (VALD-04)
6. Validation results logged to console for human review
7. Full test suite passes: `julia --project=test test/runtests.jl`
8. Extraction script is rerunnable: `julia scripts/extract_reference_data.jl docs/Sample/DS_ONS_102025_RV2D11/`
</verification>

<success_criteria>
- Integration test loads ONS sample data DS_ONS_102025_RV2D11 and solves without errors (VALD-01)
- Total cost comparison executes with 5% tolerance (VALD-02 - pass or fail with diagnostics)
- PLD comparison executes with pass-rate threshold approach (VALD-03 - pass or fail with diagnostics)
- Validation report documents all metrics with expected vs actual values (VALD-04)
- Reference CSV files committed in expected/ directory
- Full test suite passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/05-end-to-end-validation/05-04-SUMMARY.md`
</output>
