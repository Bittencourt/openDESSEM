---
phase: 02-hydro-modeling-completion
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/data/loaders/dessem_loader.jl
  - src/entities/hydro.jl
autonomous: true

must_haves:
  truths:
    - "Inflow data loads from dadvaz.dat files using parse_dadvaz"
    - "Daily inflows are distributed to hourly periods (daily/24)"
    - "Inflows are accessible to constraint builders via plant data or system"
    - "Inflow data matches plant IDs from hidr.dat loading"
  artifacts:
    - path: "src/data/loaders/dessem_loader.jl"
      provides: "Inflow loading integration"
      contains: "load_inflow_data|dadvaz"
      exports: ["load_dessem_case"]
    - path: "src/entities/hydro.jl"
      provides: "Inflow storage in hydro plants (optional field addition)"
  key_links:
    - from: "dadvaz.dat"
      to: "dessem_loader.jl"
      via: "parse_dadvaz function"
      pattern: "parse_dadvaz"
    - from: "dessem_loader.jl"
      to: "hydro plants"
      via: "inflow field or system-level storage"
      pattern: "inflow"
---

<objective>
Load hydrological inflow data from dadvaz.dat DESSEM files and integrate into the loading pipeline.

Purpose: Replace hardcoded zero inflows with actual forecast data from official DESSEM files. The dadvaz.dat file contains daily inflow forecasts per plant in m続/s, which must be distributed to hourly periods.

Output: InflowData struct, load_inflow_data() function, integration with load_dessem_case() to attach inflows to hydro plants.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-hydro-modeling-completion/02-CONTEXT.md
@.planning/phases/02-hydro-modeling-completion/02-RESEARCH.md
@src/data/loaders/dessem_loader.jl
@src/entities/hydro.jl
</context>

<tasks>

<task type="auto">
  <name>Add inflow loading to DessemLoader</name>
  <files>src/data/loaders/dessem_loader.jl</files>
  <action>
Modify `src/data/loaders/dessem_loader.jl` to add inflow data loading:

1. **Verify parse_dadvaz is imported** (already at line 63):
   - Confirm `parse_dadvaz` is in the using DESSEM2Julia statement

2. **Create InflowData struct** (after the existing DessemCaseData struct, around line 200):
   ```julia
   """
       InflowData

   Container for hydrological inflow time series loaded from dadvaz.dat.
   
   # Fields
   - `inflows::Dict{Int,Vector{Float64}}`: Plant number => hourly inflow (m続/s)
   - `num_periods::Int`: Number of time periods
   - `start_date::Date`: Start date of inflow data
   """
   struct InflowData
       inflows::Dict{Int,Vector{Float64}}  # plant_number => hourly inflows m続/s
       num_periods::Int
       start_date::Date
   end
   ```

3. **Create load_inflow_data() function**:
   ```julia
   """
       load_inflow_data(dessem_path::String) -> InflowData

   Load hydrological inflow forecasts from dadvaz.dat file.

   # Arguments
   - `dessem_path::String`: Path to DESSEM case directory

   # Returns
   - `InflowData`: Container with hourly inflows per plant

   # File Format
   dadvaz.dat contains daily inflows in m続/s. Daily values are distributed
   evenly to hourly periods (daily_inflow / 24).

   # Example
   ```julia
   inflow_data = load_inflow_data("path/to/DS_ONS_102025_RV2D11/")
   inflow_data.inflows[1]  # Hourly inflows for plant 1 (CAMARGOS)
   ```
   """
   function load_inflow_data(dessem_path::String)
       # Find dadvaz.dat file
       dadvaz_path = joinpath(dessem_path, "dadvaz.dat")
       
       if !isfile(dadvaz_path)
           @warn "dadvaz.dat not found, inflows will be zero" path=dadvaz_path
           return InflowData(Dict{Int,Vector{Float64}}(), 0, Date(2000, 1, 1))
       end
       
       # Parse using DESSEM2Julia
       dadvaz_data = parse_dadvaz(dadvaz_path)
       
       # Convert daily to hourly and build inflows dict
       inflows = Dict{Int,Vector{Float64}}()
       
       # The parse_dadvaz returns data structure with plant inflows
       # Extract and convert: daily_m3s / 24 for each hour
       for (plant_num, daily_inflows) in dadvaz_data.inflows
           hourly = Float64[]
           for daily_val in daily_inflows
               # Distribute daily inflow evenly across 24 hours
               hourly_val = daily_val / 24.0
               for _ in 1:24
                   push!(hourly, hourly_val)
               end
           end
           inflows[plant_num] = hourly
       end
       
       num_periods = isempty(inflows) ? 0 : length(first(values(inflows)))
       start_date = Date(2000, 1, 1)  # Default, could parse from file
       
       return InflowData(inflows, num_periods, start_date)
   end
   ```

4. **Update load_dessem_case()** to call load_inflow_data():
   - Find the function `load_dessem_case(dessem_path::String)`
   - After loading hydro plants, add:
   ```julia
   # Load inflow data from dadvaz.dat
   inflow_data = load_inflow_data(dessem_path)
   ```
   
5. **Store inflow data for later use** - Two options:
   - Option A (preferred): Add `inflow_data::InflowData` field to DessemCaseData struct
   - Option B: Pass inflow_data to hydro plant conversion and store in metadata
   
   Use Option A: Add to DessemCaseData struct:
   ```julia
   struct DessemCaseData
       # ... existing fields ...
       inflow_data::InflowData
   end
   ```

6. **Export InflowData and load_inflow_data**:
   - Add to export statement: `InflowData, load_inflow_data`

Note: The actual parse_dadvaz return type from DESSEM2Julia may differ. Check the DESSEM2Julia source or inspect the parsed data structure. Adjust the extraction logic accordingly.
</action>
  <verify>
Commands:
```bash
# Check for InflowData struct
grep -q "struct InflowData" src/data/loaders/dessem_loader.jl && echo "InflowData struct found"

# Check for load_inflow_data function
grep -q "function load_inflow_data" src/data/loaders/dessem_loader.jl && echo "load_inflow_data found"

# Check for dadvaz parsing
grep -q "parse_dadvaz" src/data/loaders/dessem_loader.jl && echo "parse_dadvaz usage found"

# Check for daily to hourly conversion
grep -q "/ 24" src/data/loaders/dessem_loader.jl && echo "Daily to hourly conversion found"

# Run existing tests
julia --project=test -e 'using Test; include("test/runtests.jl")'
```
</verify>
  <done>InflowData struct created, load_inflow_data() function parses dadvaz.dat using parse_dadvaz, distributes daily inflows to hourly (daily/24), returns InflowData. Function integrated into load_dessem_case().</done>
</task>

<task type="auto">
  <name>Attach inflows to hydro plants during loading</name>
  <files>src/data/loaders/dessem_loader.jl, src/entities/hydro.jl</files>
  <action>
Connect inflow data to hydro plants so constraint builders can access it.

**Option 1 (Preferred - No entity modification):**
Store inflow data in DessemCaseData and have constraint builders look up inflows by plant number.

1. **In load_dessem_case()**, after creating all hydro plants:
   ```julia
   # Create mapping from plant ID to plant number for inflow lookup
   plant_id_to_number = Dict{String,Int}()
   for (plant_num, _) in inflow_data.inflows
       # Find the hydro plant with this plant number
       # Plant IDs are like "H_SE_001" where 001 is the plant number
       # Need to match based on subsystem_code and plant number from hidr.dat
   end
   ```

2. **Update DessemCaseData** to include a mapping:
   ```julia
   struct DessemCaseData
       thermal_plants::Vector{ConventionalThermal}
       hydro_plants::Vector{ReservoirHydro}
       # ... other fields ...
       inflow_data::InflowData
       # Mapping: plant_id => plant_number for inflow lookup
       hydro_plant_numbers::Dict{String,Int}
   end
   ```

**Option 2 (Add inflow field to hydro entities):**
Add an optional `inflows::Union{Vector{Float64},Nothing}` field to ReservoirHydro, RunOfRiverHydro, PumpedStorageHydro.

For Phase 2, use **Option 1** to avoid modifying entity structs. The constraint builder can look up inflows using the mapping.

3. **In load_dessem_case()**, build the plant_numbers mapping:
   ```julia
   # Build plant ID to number mapping from hidr.dat data
   # The hidr.dat plant numbers correspond to inflow plant numbers
   hydro_plant_numbers = Dict{String,Int}()
   
   for (idx, hidr_record) in enumerate(hidr_data.records)
       plant_id = hydro_plant_ids[idx]  # From earlier conversion
       hydro_plant_numbers[plant_id] = idx  # Or hidr_record.number if available
   end
   ```

4. **Update convert_dessem_hydro()** signature if needed to accept plant number:
   The function already knows the plant number from iteration, so no signature change needed.

5. **Ensure DessemCaseData is returned with both inflow_data and hydro_plant_numbers**.

This approach keeps entities clean and allows constraint builders to look up inflows.
</action>
  <verify>
Commands:
```bash
# Check for hydro_plant_numbers in DessemCaseData
grep -q "hydro_plant_numbers" src/data/loaders/dessem_loader.jl && echo "Plant number mapping found"

# Check that load_dessem_case builds the mapping
grep -A 100 "function load_dessem_case" src/data/loaders/dessem_loader.jl | grep -q "hydro_plant_numbers" && echo "Mapping built in load_dessem_case"

# Run existing tests
julia --project=test -e 'using Test; include("test/runtests.jl")'
```
</verify>
  <done>DessemCaseData includes inflow_data and hydro_plant_numbers mapping. Constraint builders can look up hourly inflows by plant ID using the mapping and InflowData.inflows dict.</done>
</task>

</tasks>

<verification>
After both tasks complete:
1. load_inflow_data() successfully parses dadvaz.dat from sample data
2. Daily inflows are divided by 24 to get hourly values
3. DessemCaseData contains inflow_data with non-empty inflows dict
4. hydro_plant_numbers maps plant IDs to plant numbers
5. All existing tests pass
</verification>

<success_criteria>
- InflowData struct defined with inflows Dict{Int,Vector{Float64}}
- load_inflow_data() parses dadvaz.dat using parse_dadvaz
- Daily inflows distributed to hourly (daily/24)
- DessemCaseData includes inflow_data and hydro_plant_numbers
- Constraint builders can look up inflows by plant ID
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-hydro-modeling-completion/02-02-SUMMARY.md`
</output>
